<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="4JC7EJ-1Ct_HZ1ux1gnHOytzrAzDi3yggoVSJ1qz6mU"> <meta name="msvalidate.01" content="F19304186CE5280F45A02F988A3CE3C0"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Davide Torielli </title> <meta name="author" content="Davide Torielli"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="Robotics, Enginner, toridebraus, torydebra, tory_debra# add your own keywords or leave empty"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/userIcon.svg?2d8bc00086b3edffbb1f0b0587220b37"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://torydebra.github.io/"> <link rel="stylesheet" href="/assets/css/publications.css?d41d8cd98f00b204e9800998ecf8427e"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/posters/">Dissemination Posters </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Github Repos </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Davide</span> Torielli </h1> <p class="desc">Robotics Engineer, Postdoc Researcher</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?5d7fe04c4c922460f7743fd80a893286" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <h1 id="about">About</h1> <p>I am a Roboticist Researcher currently working at <a href="https://hhcm.iit.it/en-US/" rel="external nofollow noopener" target="_blank">HHCM lab</a>, <a href="https://www.iit.it/en-US/home" rel="external nofollow noopener" target="_blank">IIT</a>, <a href="https://maps.app.goo.gl/pgYbVC4x6tkYCBFh6" rel="external nofollow noopener" target="_blank">Genova</a>, finish<s>ing</s>ed my PhD with <a href="https://biorob.phd.unige.it/" rel="external nofollow noopener" target="_blank">University of Genova</a>. The proof is <a href="https://www.iit.it/people-details/-/people/davide-torielli" rel="external nofollow noopener" target="_blank">here</a>.</p> <p>I work with cool robots trying to make them do what I want. Sometimes, I succeed (<a href="https://www.youtube.com/playlist?list=PLT9OgUePJDXWH4lcZZhrPfMZts92yIb38" rel="external nofollow noopener" target="_blank">youtube playlist</a>)</p> <p>According to my <s>tentative</s> PhD thesis title, <em>Intuitive Human-Robot Interfaces Leveraging on Autonomy Features for the Control of Highly-redundant Robots</em>, I am exploring human-robot interfaces to let people operate such highly-redundant robots. The poster <a href="https://torydebra.github.io/projects/poster_phd/">here</a> could be a good recap. With the HHCM lab, I am involved in different European projects, like H2020 <a href="https://project-sophia.eu/" rel="external nofollow noopener" target="_blank">SOPHIA</a>, H2020 <a href="https://concertproject.eu/" rel="external nofollow noopener" target="_blank">CONCERT</a>, H2020 <a href="https://clem.diism.unisi.it/~haria/" rel="external nofollow noopener" target="_blank">HARIA</a>, H2020 <a href="https://cordis.europa.eu/project/id/101120731" rel="external nofollow noopener" target="_blank">MAGICIAN</a> and in the Italian MISE founded project <a href="https://relax.comiteg.it/" rel="external nofollow noopener" target="_blank">RELAX</a>. I worked in the ROS End-Effector ROS-Industrial Focused Technical Project <a href="https://cordis.europa.eu/project/id/732287" rel="external nofollow noopener" target="_blank">ROSEE ROSIN FTP</a>. I published my <a href="https://torydebra.github.io/publications/">works</a> on journals (RAL, JIRS), and presented them at conferences (ICAR, ICRA, IROS, HUMANOIDS). I have had also the opportunity to partecipate to two ROSCON conferences, <a href="https://roscon.ros.org/2022/" rel="external nofollow noopener" target="_blank">2022</a>, <a href="https://roscon.ros.org/2023/" rel="external nofollow noopener" target="_blank">2023</a>. I love the open-sourceness of the robotic community.</p> <p>I like to eat, travel (as everyone I suppose), code stuff (btw, check my conference/school list <a href="https://torydebra.github.io/AwesomeRoboticsConferencesAndSchoolsList/">website</a>), gym, playing an instrument.</p> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0A6694"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7083369" rel="external nofollow noopener" target="_blank">RA-L</a> </abbr> </div> <div id="TPO0" class="col-sm-8"> <div class="title">TelePhysicalOperation: Remote Robot Control Based on a Virtual “Marionette” Type Interaction Interface</div> <div class="author"> <em>Davide Torielli</em>, <a href="https://www.iit.it/people-details/-/people/luca-muratore" rel="external nofollow noopener" target="_blank">Luca Muratore</a>, <a href="https://www.iit.it/people-details/-/people/arturo-laurenzi" rel="external nofollow noopener" target="_blank">Arturo Laurenzi</a>, and <a href="https://www.iit.it/people-details/-/people/nikos-tsagarakis" rel="external nofollow noopener" target="_blank">Nikos Tsagarakis</a> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/LRA.2022.3144792" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9696192" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/tpo.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.youtube.com/embed/dkBmbTyO_GQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="/assets/pdf/ICRA22_POSTER.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="badges"> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/LRA.2022.3144792"></span> <span class="__dimensions_badge_embed__" data-doi="10.1109/LRA.2022.3144792" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Teleoperation permits to control robots from a safe distance while performing tasks in a remote environment. Kinematic differences between the input device and the remotely controlled manipulator or the existence of redundancy in the remote robot may pose challenges in moving intuitively the remote robot as desired by the human operator. Motivated by the above challenges, this work introduces TelePhysicalOperation, a novel teloperation concept, which relies on a virtual physical interaction interface between the human operator and the remote robot in a manner that is equivalent to a “Marionette” based interaction interface. With the proposed approach, the user can virtually “interact” with the remote robot, through the application of virtual forces, which are generated by the operator tracking system and can be then selectively applied to any body part of the remote robot along its kinematic chain. This leads to the remote robot generating motions that comply with the applied virtual forces, thanks to the underlying control architecture. The proposed method permits to command the robot from a distance by exploring the intuitiveness of the “Marionette” based physical interaction with the robot in a virtual/remote manner. The details of the proposed approach are introduced and its effectiveness is demonstrated through a number of experimental trials executed on the CENTAURO, a hybrid leg-wheel platform with an anthropomorphic upper body.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">TPO0</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TelePhysicalOperation: Remote Robot Control Based on a Virtual “Marionette” Type Interaction Interface}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Torielli, Davide and Muratore, Luca and Laurenzi, Arturo and Tsagarakis, Nikos}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{IEEE} Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2479-2486}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/LRA.2022.3144792}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/9696192}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">RAS</abbr> </div> <div id="LaserJournal" class="col-sm-8"> <div class="title">An intuitive tele-collaboration interface exploring laser-based interaction and behavior trees</div> <div class="author"> <em>Davide Torielli</em>, <a href="https://www.iit.it/people-details/-/people/luca-muratore" rel="external nofollow noopener" target="_blank">Luca Muratore</a>, and <a href="https://www.iit.it/people-details/-/people/nikos-tsagarakis" rel="external nofollow noopener" target="_blank">Nikos Tsagarakis</a> </div> <div class="periodical"> <em>Robotics and Autonomous Systems</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/https://doi.org/10.1016/j.robot.2025.105054" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S092188902500140X" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://youtu.be/zin8LRSNwWo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-doi="https://doi.org/10.1016/j.robot.2025.105054"></span> <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1016/j.robot.2025.105054" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>The recent advancements in the development of robotic systems that offer advanced loco-manipulation capabilities have opened new opportunities in the employment of such platforms in various domains. However, despite the increased range of offered capabilities, the collaboration with these robotic platforms to execute tasks through common human–robot interaction interfaces is still an open challenge. In this article, we present a novel human–robot interaction interface that permits to intuitively command and control the manipulation and the locomotion abilities of the robot by exploring a visual servoing guidance method realized with a laser emitter device. By pointing the laser to locations and objects in the environment where the robot is operating, the operator is able to command even highly articulated robots intuitively and efficiently. The detection of the laser projection is performed by a neural network that provides robust and real-time tracking of laser spot. Combined with the responsiveness of the laser detection, a Behavior Trees-based motion planner is employed to reactively select and generate the autonomous robot motions to reach the indicated target. This combination allows the operator to communicate goal locations and paths to follow without requiring prior knowledge of the system, and without worrying about the generation of the potential complex loco-manipulation robot actions. The effectiveness of the proposed interface is demonstrated with the CENTAURO robot, a hybrid leg-wheel platform with an anthropomorphic upper body, exploiting its abilities to accomplish a number of locomotion and manipulation tasks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">LaserJournal</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An intuitive tele-collaboration interface exploring laser-based interaction and behavior trees}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Torielli, Davide and Muratore, Luca and Tsagarakis, Nikos}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Robotics and Autonomous Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{193}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{105054}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0921-8890}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.robot.2025.105054}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S092188902500140X}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Human-robot interface, Human-centered robotics, Visual servoing, Motion planning}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#0A6694"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7083369" rel="external nofollow noopener" target="_blank">RA-L</a> </abbr> </div> <div id="LaserRAL" class="col-sm-8"> <div class="title">A Laser-Guided Interaction Interface for Providing Effective Robot Assistance to People With Upper Limbs Impairments</div> <div class="author"> <em>Davide Torielli</em>, <a href="https://www.iit.it/people-details/-/people/liana-bertoni" rel="external nofollow noopener" target="_blank">Liana Bertoni</a>, <a href="https://www.iit.it/people-details/-/people/luca-muratore" rel="external nofollow noopener" target="_blank">Luca Muratore</a>, and <a href="https://www.iit.it/people-details/-/people/nikos-tsagarakis" rel="external nofollow noopener" target="_blank">Nikos Tsagarakis</a> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/LRA.2024.3430709" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10602529" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/laserRal.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://youtu.be/WyWfgpezwRs" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="badges"> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-doi="10.1109/LRA.2024.3430709"></span> <span class="__dimensions_badge_embed__" data-doi="10.1109/LRA.2024.3430709" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Robotics has shown significant potential in assisting people with disabilities to enhance their independence and involvement in daily activities. Indeed, a societal long-term impact is expected in home-care assistance with the deployment of intelligent robotic interfaces. This work presents a human-robot interface developed to help people with upper limbs impairments, such as those affected by stroke injuries, in activities of everyday life. The proposed interface leverages on a visual servoing guidance component, which utilizes an inexpensive but effective laser emitter device. By projecting the laser on a surface within the workspace of the robot, the user is able to guide the robotic manipulator to desired locations, to reach, grasp and manipulate objects. Considering the targeted users, the laser emitter is worn on the head, enabling to intuitively control the robot motions with head movements that point the laser in the environment, which projection is detected with a neural network based perception module. The interface implements two control modalities: the first allows the user to select specific locations directly, commanding the robot to reach those points; the second employs a paper keyboard with buttons that can be virtually pressed by pointing the laser at them. These buttons enable a more direct control of the Cartesian velocity of the end-effector and provides additional functionalities such as commanding the action of the gripper. The proposed interface is evaluated in a series of manipulation tasks involving a 6DOF assistive robot manipulator equipped with 1DOF beak-like gripper. The two interface modalities are combined to successfully accomplish tasks requiring bimanual capacity that is usually affected in people with upper limbs impairments.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">LaserRAL</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Torielli, Davide and Bertoni, Liana and Muratore, Luca and Tsagarakis, Nikos}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Laser-Guided Interaction Interface for Providing Effective Robot Assistance to People With Upper Limbs Impairments}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{IEEE} Robotics and Automation Letters}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7653-7660}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/LRA.2024.3430709}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Robots;Lasers;Task analysis;Keyboards;Magnetic heads;Surface emitting lasers;Grippers;Human-robot collaboration;physically assistive devices;visual servoing}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/10602529}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#242B66"> <a href="https://www.springer.com/journal/10846" rel="external nofollow noopener" target="_blank">JIRS</a> </abbr> </div> <div id="ROSEE" class="col-sm-8"> <div class="title">ROS End-Effector: A Hardware-Agnostic Software and Control Framework for Robotic End-Effectors</div> <div class="author"> <em>Davide Torielli</em>, <a href="https://www.iit.it/people-details/-/people/liana-bertoni" rel="external nofollow noopener" target="_blank">Liana Bertoni</a>, <a href="https://www.linkedin.com/in/fabio-fusaro-69aa361a4/?originalSubdomain=it" rel="external nofollow noopener" target="_blank">Fabio Fusaro</a>, <a href="https://www.iit.it/people-details/-/people/nikos-tsagarakis" rel="external nofollow noopener" target="_blank">Nikos Tsagarakis</a>, and <a href="https://www.iit.it/people-details/-/people/luca-muratore" rel="external nofollow noopener" target="_blank">Luca Muratore</a> </div> <div class="periodical"> <em>Journal of Intelligent &amp; Robotic Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s10846-023-01911-5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s10846-023-01911-5" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/rosee.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://www.youtube.com/embed/X0qpSsFQg1M" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/ADVRHumanoids/ROSEndEffector" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-doi="10.1007/s10846-023-01911-5"></span> <span class="__dimensions_badge_embed__" data-doi="10.1007/s10846-023-01911-5" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In recent years, several robotic end-effectors have been developed and made available in the market. Nevertheless, their adoption in industrial context is still limited due to a burdensome integration, which strongly relies on customized software modules specific for each end-effector. Indeed, to enable the functionalities of these end-effectors, dedicated interfaces must be developed to consider the different end-effector characteristics, like finger kinematics, actuation systems, and communication protocols. To face the challenges described above, we present ROS End-Effector, an open-source framework capable of accommodating a wide range of robotic end-effectors of different grasping capabilities (grasping, pinching, or independent finger dexterity) and hardware characteristics. The ROS End-Effector framework, rather than controlling each end-effector in a different and customized way, allows to mask the physical hardware differences and permits to control the end-effector using a set of high-level grasping primitives automatically extracted. By leveraging on hardware agnostic software modules including hardware abstraction layer (HAL), application programming interfaces (APIs), simulation tools and graphical user interfaces (GUIs), ROS End-Effector effectively facilitates the integration of diverse end-effector devices. The proposed framework capabilities in supporting different robotics end-effectors are demonstrated in both simulated and real hardware experiments using a variety of end-effectors with diverse characteristics, ranging from under-actuated grippers to anthropomorphic robotic hands. Finally, from the user perspective, the manuscript provides a set of examples about the use of the framework showing its flexibility in integrating a new end-effector module.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ROSEE</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10846-023-01911-5}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s10846-023-01911-5}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Science and Business Media {LLC}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{108}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Torielli, Davide and Bertoni, Liana and Fusaro, Fabio and Tsagarakis, Nikos and Muratore, Luca}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{ROS} End-Effector: A Hardware-Agnostic Software and Control Framework for Robotic End-Effectors}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Intelligent \&amp; Robotic Systems}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%74%6F%72%69%64%65%62%72%61%75%73@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/torydebra" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://ieeexplore.ieee.org/author/37089227580/" title="IEEE Xplore" rel="external nofollow noopener" target="_blank"><i class="ai ai-ieee"></i></a> <a href="https://www.linkedin.com/in/davide-torielli-838298192" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://orcid.org/0000-0002-9711-3006" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://www.researchgate.net/profile/Davide_Torielli/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> <a href="https://scholar.google.com/citations?user=KPZ7hz0AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.scopus.com/authid/detail.uri?authorId=57446004100" title="Scopus" rel="external nofollow noopener" target="_blank"><i class="ai ai-scopus"></i></a> <a href="https://www.iit.it/it/people-details/-/people/davide-torielli" title="Work" rel="external nofollow noopener" target="_blank"><i class="fa-solid fa-briefcase"></i></a> <a href="https://youtube.com/@Belintoridebraus" title="YouTube" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-youtube"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Davide Torielli. Last updated: July 29, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>